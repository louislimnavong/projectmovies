---
title: "R Notebook"
output: html_notebook
---


First, we install and load the librairies needed to create the functions. 

```{r}
install.packages("igraph")
install.packages("shinythemes")
library(dplyr)
library(tidyr)
library(igraph)
```

We used the data set 'tmdb_5000_movies.csv', found on Kaggle, to get a list of movies and characteristics. 
The code below imports the data set. The path has to be replaced by the one linked to the working directory.

The first step to clean the data set is to remove the movies with no keywords in common with other movies from the data set. 

```{r}
# PATH TO CHANGE 

tmdb <- read.csv("/Users/path/to/file/tmdb_5000_movies.csv",stringsAsFactors = FALSE) 
tmdb<-tmdb[-c(382,294,168,345,72,313,318,303,458,84,444,87,493,437,324), ]
#These rows are deleted due to a lack of keywords with other movies

```

The columns will the use to create the similarity matrix (adjency matrix for the graph) are 'genres' and 'keywords'. 
Those columns are not usable in the initial state (factors of length 1), hence, we need to split them into different columns. A cell of a column would only include one genre (or one keyword).

```{r}
# GENRES CLEANING CODE 

tmdb1 <- tmdb 
tmdb1 <- tmdb1 %>% mutate(genres = gsub('"name"', "", genres)) # replace the string "name" by the empty string 
tmdb1 <- tmdb1 %>% mutate(genres = gsub('"id"', "", genres))
tmdb1 <- tmdb1 %>% mutate(genres = chartr('}"][}{:1234567890', '                 ', genres))  
tmdb1 <- tmdb1 %>% mutate(genres = gsub(" ", "", genres))
tmdb1 <- tmdb1 %>% separate(genres,into = c("null", "1", "null1", "2", "null2", "3", "null3","4","null4", "5", "null5", "6"),sep = ',' ,remove = TRUE)
movies <- tmdb1[c(1,3,5,7,9,11,13,18)]
movies <- movies[-1]
View(movies)

matrix_movies <- as.matrix(movies)
```

The code bellow cleans the column for the keywords and split the columns into different columns for every keyword.


```{r}

# Keywords CLEANING CODE 
tmp <- c(1:40)
tmp <- as.character(tmp)

tmdb2 <- tmdb %>% mutate(keywords = gsub('"name"', "", keywords))
tmdb2 <- tmdb2 %>% mutate(keywords = gsub('"id"', "", keywords))
tmdb2 <- tmdb2 %>% mutate(keywords = chartr('}"][}{:1234567890', '                 ', keywords))
tmdb2 <- tmdb2 %>% mutate(keywords = gsub(" ", "", keywords))
tmdb2 <- tmdb2[c(5,7,9,11,13,18)]
tmdb2 <- tmdb2 %>% separate(keywords,into = tmp ,sep = ',' ,remove = TRUE)
movies2 <- tmdb2[c(seq(2, 41, by=2))]
movies2$original_title<-tmdb2$original_title
View(movies2)

matrix_movies2 <- as.matrix(movies2)
matrix_movies2[ matrix_movies2 == "d" ] <- NA
```

We also create the matrix from the data set to get the length of the intersection for given rows. This length is equal to the number of genres (or keywords) that two movies have in common.

For two given rows, we create three functions : 
- score_genre gives the number of genres in commmon between two movies, 
- score_keywords gives the number of keywords in commmon between two movies, 
- score_total aggregates those two scores. 


```{r}
# Score function 

score_genre <- function(i,j) {
  vector_movies <- intersect(matrix_movies[i,],matrix_movies[j,])
  vector_movies <- vector_movies[!is.na(vector_movies)]
  if  (length(vector_movies) != 0){
    result = length(vector_movies)
    }
  else {
    result = 0 
  }
}

score_key <- function(i,j) {
  vector_movies <- intersect(matrix_movies2[i,],matrix_movies2[j,])
  vector_movies <- vector_movies[!is.na(vector_movies)]
  length(vector_movies)
}

score_total <- function(i,j) {
  result = score_key(i,j) + score_genre(i,j)
}

```

Our goal is to find the path with maximal similarities by finding the path with the minimal weight in a graph. Therefore, the weight function should be the inverse of the score. 
Moreover, the decide to put an edge between two movies only if they share a keywords. 

Here, we create the weight function between two movies. The smallest the weight is, the more similar two movies are. 


```{r}
weight <- function(i,j) {
  if (i>= j) {
    result = NA
  }
  else {
    if (score_key(i,j) == 0) {
        result = 0
    }
    else {
    result = 1/(score_total(i,j))
    }
  }
    print(result)
}
```

Given the weight function, we can generate an adjacency matrix to create a graph. 
Here, we vectorize the weight function to use the outer function that creates the adjacency matrix (which defines our graph). We also need to assign 0 to the diagonal so that vertices do not have self edges. 


```{r}

VecWeight <- Vectorize( weight )

graph_matrix <- outer(seq(1,500),seq(1,500),VecWeight) 
diag(graph_matrix) = 0 
movies_used <- movies[1:500,] 

graph <- graph_from_adjacency_matrix(graph_matrix, mode = c("undirected"), weighted = T)
plot(graph)


```

Given two names of movies, this function calculates the shortest path between them and converts the output into a dataframe (for shiny app compatibility)

```{r}


movies_path <- function(names) {
  i <- which(movies2$original_title == names[1])
  j <- which(movies2$original_title == names[2])
  l <- shortest_paths(graph, i,j)
  l1 <- l[[1]][[1]]
  movies_list <- list()
  for (i in 1:length(l1)){
    movies_list[[i]] <- tmdb$original_title[l1[i]]
  }
  movies_list <- do.call(rbind.data.frame, movies_list)
  colnames(movies_list) <- c("Pathway from first movie to second movie")
  print(movies_list)
  
}



```

Given two movies, this chunk outputs the genres and the keywords they have in common.

```{r}

similarities_key <- function(names) {
  i <- which(movies2$original_title == names[1])
  j <- which(movies2$original_title == names[2])
  keywords <- intersect(matrix_movies2[i,],matrix_movies2[j,])
  keywords <- keywords[!is.na(keywords)]
  print(paste(keywords))
  
  
}
similarities_key(c("The Dark Knight Rises","Superman Returns"))

similarities_genre <- function(names) {
  i <- which(movies2$original_title == names[1])
  j <- which(movies2$original_title == names[2])
  genre <- intersect(matrix_movies[i,],matrix_movies[j,])
  genre <- genre[!is.na(genre)]
  print(paste(genre))
  
  
}
similarities_genre(c("The Dark Knight Rises","Superman Returns"))

```

Here we created a test adjacency matrix (which defines a network) to check whether the shortest path function calculates the path based on the smallest number of edges or the path with the lowest sum of weights. As can be seen when running this chunck it calculates the latter. Vertices 1 & 2 are connected by an edge of weight 10, which constitutes a path of length 1 with weight 10. When implementing the shortes path algorithm though, the output is the path from 1 to 3 and 3 to 2, which has length 2 but weight 2+2=4.

```{r}
# TEST the function shortest_paths
m <- outer(seq(1,3),seq(1,3),"+")
diag(m) = 0
m[2,1] = NA
m[1,2] = 10
m[3,1] = 2
m[1,3] = 2
m[3,2] = 2
m[2,3] = 2
m
g <- graph_from_adjacency_matrix(m,mode = c("undirected"), weighted = T)
plot(g)
shortest_paths(g,1,2)
distances(g,2,1)
```

Below we calculated the runtime of creating the adjacency matrix for the graph.
The original dataset consisted out of 4803 movies, this however resulted in a matrix of almost 25000000 entries, each of which calls the weight function. Due to this the runtime was extremely long. By using this chunch below we searched for the optimal amount of movies with an acceptable runtime. The result was a dataset of 500 movies (with a runtime of roughly 3 minutes) instead of 4803. With a stronger processor one could run the same shiny app on the whole dataset.

```{r}
# Runtime 
start_time <- Sys.time()
graph_matrix <- outer(seq(1,500),seq(1,500),VecWeight) 
end_time <- Sys.time()
end_time - start_time
```




